# Gesture Classification Inference Applications

This directory contains real-time gesture classification inference applications that use trained models to classify gestures from live camera feed or video files.

![Interface Screenshot](interface_classification.jpg)

## üöÄ Quick Start

### 1. Check if Models Exist
```bash
python run_inference.py --check-models
```

### 2. Run GUI Application
```bash
python run_inference.py --mode gui
```

### 3. Run CLI Application
```bash
python run_inference.py --mode cli
```

## üìÅ Files Overview

### Core Applications
- **`inference_app.py`** - GUI application with real-time camera feed
- **`inference_cli.py`** - Command-line interface for batch processing
- **`run_inference.py`** - Launcher script for easy access

### Supporting Files
- **`inference.py`** - Core inference engine (legacy)
- **`gesture_classifier.py`** - Model management and training utilities

## üéØ Features

### GUI Application (`inference_app.py`)
- **Real-time camera feed** with pose detection overlay
- **Live gesture classification** with confidence scores
- **Model selection** (Random Forest, SVM, Neural Network)
- **Confidence threshold** adjustment
- **Top predictions** display
- **System information** panel

### CLI Application (`inference_cli.py`)
- **Video file processing** for batch analysis
- **Live camera prediction** with duration control
- **Confidence threshold** filtering
- **Model selection** options
- **Summary statistics** for video analysis

## üõ†Ô∏è Usage Examples

### GUI Application
```bash
# Start GUI with default settings
python inference_app.py

# Or use the launcher
python run_inference.py --mode gui
```

**GUI Controls:**
- **Start Camera** - Begin live prediction
- **Stop Camera** - End prediction session
- **Model** - Select which trained model to use
- **Confidence Threshold** - Adjust minimum confidence (0.0-1.0)

### CLI Application

#### Process Video File
```bash
python inference_cli.py \
    --video "path/to/video.mp4" \
    --confidence 0.7 \
    --model neural_network
```

#### Live Camera Prediction
```bash
python inference_cli.py \
    --camera \
    --duration 30 \
    --confidence 0.8
```

#### Check Available Models
```bash
python inference_cli.py --models-dir models_2class --help
```

## üìä Output Examples

### CLI Video Processing
```
[OK] Loaded random_forest model
[OK] Loaded svm model
[OK] Loaded neural_network model
[OK] Best model: neural_network
[OK] Classes: ['g1', 'g2']
[OK] Using model: neural_network
[OK] Confidence threshold: 0.7
Processing video: video.mp4
Frame 30: g1 (confidence: 0.994)
Frame 60: g1 (confidence: 0.987)
Frame 90: g1 (confidence: 0.992)

[SUMMARY]
Total predictions: 24
g1: 24 predictions
```

### GUI Real-time Display
- **Current Prediction**: üéØ g1
- **Confidence**: 0.994
- **Top Predictions**:
  1. g1: 0.994
  2. g2: 0.006

## üîß Technical Details

### Model Requirements
- **Trained models** must exist in `models_2class/` directory
- **Metadata file**: `gesture_multiclass_metadata.json`
- **Model files**: `gesture_multiclass_*.joblib`

### Feature Extraction
- **MediaPipe pose landmarks** (33 points)
- **Geometric features** (23 features per frame):
  - Joint angles (12 features)
  - Body proportions (3 features)
  - Center of mass (3 features)
  - Arm/leg extensions (4 features)
  - Body orientation (1 feature)

### Frame Processing
- **Target frames**: 30 frames per prediction
- **Zero padding**: For videos with <30 frames
- **Buffer management**: Sliding window approach

## üé® GUI Interface

### Layout
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Camera Feed   ‚îÇ   Predictions   ‚îÇ
‚îÇ                 ‚îÇ                 ‚îÇ
‚îÇ                 ‚îÇ Current: g1     ‚îÇ
‚îÇ                 ‚îÇ Confidence: 0.99‚îÇ
‚îÇ                 ‚îÇ                 ‚îÇ
‚îÇ                 ‚îÇ Top Predictions:‚îÇ
‚îÇ                 ‚îÇ 1. g1: 0.994   ‚îÇ
‚îÇ                 ‚îÇ 2. g2: 0.006   ‚îÇ
‚îÇ                 ‚îÇ                 ‚îÇ
‚îÇ                 ‚îÇ System Info:    ‚îÇ
‚îÇ                 ‚îÇ Frames: 30/30   ‚îÇ
‚îÇ                 ‚îÇ Model: Neural Net‚îÇ
‚îÇ                 ‚îÇ Threshold: 0.70 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Controls Panel
- **Start/Stop Camera** buttons
- **Model selection** dropdown
- **Confidence threshold** slider (0.0-1.0)

## üö® Troubleshooting

### Common Issues

#### 1. Models Not Found
```
[ERROR] Metadata not found: models_2class/gesture_multiclass_metadata.json
```
**Solution**: Train models first using `train_multiclass_mediapipe.py`

#### 2. Camera Not Opening
```
Failed to open camera
```
**Solution**: 
- Check camera permissions
- Try different camera index: `--camera-index 1`
- Ensure no other applications are using the camera

#### 3. Low Confidence Predictions
```
Frame 30: Uncertain (confidence: 0.45)
```
**Solution**:
- Lower confidence threshold
- Ensure good lighting
- Check pose visibility
- Verify model training quality

#### 4. Unicode Display Issues
**Solution**: Use the launcher script `run_inference.py` which handles encoding properly

### Performance Tips

1. **Lighting**: Ensure good, even lighting for pose detection
2. **Distance**: Stand 2-3 meters from camera for optimal pose detection
3. **Background**: Use plain background to avoid pose confusion
4. **Clothing**: Wear contrasting colors for better landmark detection
5. **Stability**: Hold poses for 1-2 seconds for better predictions

## üìà Model Performance

Based on training results:
- **Neural Network**: Best overall performance (84.62% accuracy)
- **Random Forest**: Good performance with fast inference
- **SVM**: Moderate performance, good for simple gestures

## üîÑ Integration

### With Data Collection
The inference applications work seamlessly with the data collection system:
1. **Collect data** using `desktop/app.py`
2. **Train models** using `train_multiclass_mediapipe.py`
3. **Run inference** using these applications

### Custom Models
To use custom trained models:
1. Place models in appropriate directory
2. Update metadata file with class names
3. Modify `models_dir` parameter in applications

## üìù Notes

- **Real-time performance**: ~30 FPS on modern hardware
- **Memory usage**: ~200MB for GUI application
- **Dependencies**: MediaPipe, OpenCV, PySide6 (GUI), scikit-learn
- **Platform**: Windows, macOS, Linux (with appropriate camera drivers)

## üéâ Success Metrics

The inference applications successfully demonstrate:
- ‚úÖ **Real-time classification** with high accuracy
- ‚úÖ **User-friendly interfaces** (GUI and CLI)
- ‚úÖ **Robust error handling** and validation
- ‚úÖ **Flexible model selection** and configuration
- ‚úÖ **Comprehensive logging** and feedback
